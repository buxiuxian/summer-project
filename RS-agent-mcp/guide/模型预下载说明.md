# 模型预下载说明

## 概述

本项目的RAG知识库系统需要使用多个sentence-transformers模型来进行文本嵌入和语义检索。为了避免在网络不畅时启动服务器出现问题，我们提供了模型预下载功能。

## 使用的模型

项目按优先级使用以下5个模型：

1. **all-MiniLM-L6-v2** (推荐)
   - 大小：22MB
   - 语言：英文
   - 嵌入维度：384
   - 特点：速度快，稳定性好

2. **paraphrase-multilingual-MiniLM-L12-v2**
   - 语言：多语言支持
   - 嵌入维度：384
   - 特点：支持中文等多种语言

3. **all-MiniLM-L12-v2**
   - 大小：稍大
   - 嵌入维度：384
   - 特点：效果更好的备选方案

4. **distiluse-base-multilingual-cased**
   - 语言：多语言
   - 嵌入维度：512
   - 特点：多语言中等大小模型

5. **paraphrase-MiniLM-L6-v2**
   - 大小：22MB
   - 语言：英文
   - 嵌入维度：384
   - 特点：小型备选方案

## 预下载脚本

### 运行预下载

直接运行项目根目录下的预下载脚本：

```bash
python download_models.py
```

### 脚本功能

1. **检查缓存位置** - 自动检测模型缓存目录并显示已缓存的模型
2. **批量下载模型** - 按优先级依次下载所有模型
3. **模型测试** - 验证每个模型是否能正常工作
4. **性能测试** - 测试模型加载和编码性能

### 缓存位置

模型默认缓存在以下位置：
- Windows: `C:\Users\[用户名]\.cache\huggingface\hub`
- Linux/Mac: `~/.cache/huggingface/hub`

## 工作原理

### 服务器启动时的模型加载

当服务器启动时，RAG系统会按以下顺序尝试加载模型：

1. 首先尝试 `all-MiniLM-L6-v2`
2. 如果失败，尝试 `paraphrase-MiniLM-L6-v2`
3. 继续尝试多语言模型
4. 如果所有嵌入模型都失败，降级使用TF-IDF方法

### 离线使用优势

预下载模型后的优势：

- **快速启动** - 避免网络下载等待时间
- **离线可用** - 在无网络环境下也能正常工作
- **稳定性** - 避免网络问题导致的服务启动失败
- **性能提升** - 本地加载比网络下载快得多

## 故障排除

### 常见问题

1. **网络连接问题**
   ```
   ✗ 下载模型 xxx 失败: Connection timeout
   ```
   解决方案：检查网络连接，或使用代理

2. **磁盘空间不足**
   解决方案：清理磁盘空间，所有模型总共约需要200MB空间

3. **依赖包缺失**
   ```
   SentenceTransformers未安装
   ```
   解决方案：运行 `pip install sentence-transformers`

### 验证安装

运行以下命令验证模型是否正确安装：

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode("测试文本")
print(f"嵌入维度: {len(embedding)}")
```

## 注意事项

1. **首次运行时间较长** - 下载所有模型需要几分钟时间
2. **网络要求** - 需要稳定的网络连接进行下载
3. **存储空间** - 需要约200MB的磁盘空间
4. **定期更新** - 建议定期运行脚本更新模型

## 技术细节

### 模型选择策略

RAG系统采用智能降级策略：
- 优先使用小型、快速的模型
- 如果首选模型不可用，自动切换到备选模型
- 最终降级到TF-IDF传统方法确保系统可用性

### 缓存机制

- 使用HuggingFace的标准缓存机制
- 模型只需下载一次，后续使用本地缓存
- 支持多个项目共享相同的模型缓存 