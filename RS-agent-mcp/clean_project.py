#!/usr/bin/env python3
"""
RS Agent MCP é¡¹ç›®æ¸…ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæ¸…ç†é¡¹ç›®è¿è¡Œä¸­äº§ç”Ÿçš„å„ç§æ— ç”¨æ–‡ä»¶ï¼Œç¡®ä¿é¡¹ç›®åœ¨æäº¤åˆ°GitHubæ—¶ä¿æŒæ•´æ´ã€‚

ä½¿ç”¨æ–¹æ³•:
    python clean_project.py

æ¸…ç†å†…å®¹:
    - ä¸´æ—¶æ–‡ä»¶å’Œç›®å½• (temp/, tmp/, *.tmp, *.log)
    - ç¼“å­˜æ–‡ä»¶ (__pycache__, .pytest_cache, *.pyc)
    - æ—¥å¿—æ–‡ä»¶ (logs/)
    - æµ‹è¯•äº§ç”Ÿçš„æ–‡ä»¶ (htmlcov/, .coverage)
    - çŸ¥è¯†åº“ç´¢å¼•æ–‡ä»¶ (faiss_index_domain_science.index, faiss_index_domain_science_mapping.json)
    - å¼€å‘è°ƒè¯•æ–‡ä»¶ (debug.md, progress.md)
    - ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶ (uploads/)
    - æ—§çš„ä¼šè¯æ•°æ® (sessions/)
    - IDEé…ç½®æ–‡ä»¶ (.vscode/, .idea/)

é‡è¦è¯´æ˜:
    - .claudeç›®å½•ï¼ˆç”¨æˆ·ä¸ªäººè®¾ç½®ï¼‰ä¸ä¼šè¢«æ¸…ç†
    - file_storage/ ç›®å½•ä¸ä¼šè¢«æ¸…ç†ï¼ˆåŒ…å«ç”¨æˆ·ä¸Šä¼ çš„åŸå§‹æ–‡ä»¶ï¼‰
    - file_mapping.json æ–‡ä»¶ä¸ä¼šè¢«æ¸…ç†ï¼ˆåˆ é™¤ä¼šå¯¼è‡´ä¸Šä¼ æ–‡ä»¶ä¸¢å¤±ï¼‰
    - SentenceTransformeræ¨¡å‹ç¼“å­˜ä½äºç”¨æˆ·ç›®å½•ï¼Œä¸ä¼šè¢«æ¸…ç†
    - é¡¹ç›®è®°å½•æ–‡ä»¶é»˜è®¤ä¿ç•™ï¼Œä½¿ç”¨ --include-records å‚æ•°æ¸…ç†
    - åˆ é™¤çš„ç´¢å¼•æ–‡ä»¶å¯ä»¥é€šè¿‡é‡æ–°æ„å»ºçŸ¥è¯†åº“æ¥é‡æ–°ç”Ÿæˆ
"""

import os
import shutil
import glob
import logging
from pathlib import Path
from typing import List, Dict, Any
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProjectCleaner:
    """é¡¹ç›®æ¸…ç†å™¨"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(__file__).parent
        self.cleaned_items = []
        self.failed_items = []
        
    def log_cleaned(self, item_type: str, path: str, size_mb: float = 0):
        """è®°å½•æ¸…ç†çš„é¡¹"""
        self.cleaned_items.append({
            'type': item_type,
            'path': str(path),
            'size_mb': size_mb,
            'timestamp': time.time()
        })
        
    def log_failed(self, item_type: str, path: str, error: str):
        """è®°å½•æ¸…ç†å¤±è´¥çš„é¡¹"""
        self.failed_items.append({
            'type': item_type,
            'path': str(path),
            'error': error,
            'timestamp': time.time()
        })
    
    def get_dir_size(self, path: Path) -> float:
        """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
        try:
            if path.is_file():
                return path.stat().st_size / (1024 * 1024)
            elif path.is_dir():
                total_size = 0
                for dirpath, dirnames, filenames in os.walk(path):
                    for filename in filenames:
                        file_path = os.path.join(dirpath, filename)
                        if os.path.exists(file_path):
                            total_size += os.path.getsize(file_path)
                return total_size / (1024 * 1024)
            return 0
        except (OSError, IOError):
            return 0
    
    def clean_temp_files(self) -> int:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        cleaned_count = 0
        
        temp_dirs = [
            self.project_root / "temp",
            self.project_root / "tmp",
        ]
        
        for temp_dir in temp_dirs:
            if temp_dir.exists():
                try:
                    size = self.get_dir_size(temp_dir)
                    shutil.rmtree(temp_dir)
                    temp_dir.mkdir(exist_ok=True)
                    self.log_cleaned("ä¸´æ—¶ç›®å½•", temp_dir, size)
                    cleaned_count += 1
                    logger.info(f"  âœ… å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("ä¸´æ—¶ç›®å½•", temp_dir, str(e))
                    logger.error(f"  âŒ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥ {temp_dir}: {e}")
        
        # æ¸…ç†æ ¹ç›®å½•ä¸‹çš„ä¸´æ—¶æ–‡ä»¶
        temp_patterns = [
            "*.tmp",
            "*.temp",
            "*.log",
            "*.cache",
            # æ³¨æ„ï¼š.bakæ–‡ä»¶å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šåœ¨æ­¤æ¸…ç†
            "*.swp",
            "*.swo",
            "*~",
        ]
        
        for pattern in temp_patterns:
            for file_path in self.project_root.glob(pattern):
                try:
                    if file_path.is_file():
                        size = self.get_dir_size(file_path)
                        file_path.unlink()
                        self.log_cleaned("ä¸´æ—¶æ–‡ä»¶", file_path, size)
                        cleaned_count += 1
                        logger.info(f"  âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file_path.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("ä¸´æ—¶æ–‡ä»¶", file_path, str(e))
        
        return cleaned_count
    
    def clean_cache_files(self) -> int:
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†ç¼“å­˜æ–‡ä»¶...")
        cleaned_count = 0
        
        cache_dirs = [
            self.project_root / "__pycache__",
            self.project_root / ".pytest_cache",
            self.project_root / ".mypy_cache",
            self.project_root / ".ruff_cache",
        ]
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰__pycache__ç›®å½•
        for pycache_dir in self.project_root.rglob("__pycache__"):
            cache_dirs.append(pycache_dir)
        
        for cache_dir in cache_dirs:
            if cache_dir.exists():
                try:
                    size = self.get_dir_size(cache_dir)
                    shutil.rmtree(cache_dir)
                    self.log_cleaned("ç¼“å­˜ç›®å½•", cache_dir, size)
                    cleaned_count += 1
                    logger.info(f"  âœ… å·²æ¸…ç†ç¼“å­˜ç›®å½•: {cache_dir.relative_to(self.project_root)} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("ç¼“å­˜ç›®å½•", cache_dir, str(e))
                    logger.error(f"  âŒ æ¸…ç†ç¼“å­˜ç›®å½•å¤±è´¥ {cache_dir}: {e}")
        
        # æ¸…ç†.pycæ–‡ä»¶
        for pyc_file in self.project_root.rglob("*.pyc"):
            try:
                if pyc_file.is_file():
                    size = self.get_dir_size(pyc_file)
                    pyc_file.unlink()
                    self.log_cleaned("ç¼–è¯‘æ–‡ä»¶", pyc_file, size)
                    cleaned_count += 1
            except Exception as e:
                self.log_failed("ç¼–è¯‘æ–‡ä»¶", pyc_file, str(e))
        
        return cleaned_count
    
    def clean_model_files(self) -> int:
        """æ¸…ç†æ¨¡å‹å’Œç´¢å¼•æ–‡ä»¶ï¼ˆåªåˆ é™¤å¯é‡æ–°ç”Ÿæˆçš„æ–‡ä»¶ï¼‰"""
        logger.info("ğŸ§¹ æ¸…ç†æ¨¡å‹å’Œç´¢å¼•æ–‡ä»¶...")
        cleaned_count = 0
        
        # æ³¨æ„ï¼šè¿™äº›æ–‡ä»¶å¯ä»¥é‡æ–°ç”Ÿæˆï¼Œåˆ é™¤åéœ€è¦é‡æ–°æ„å»ºçŸ¥è¯†åº“
        safe_to_delete_patterns = [
            # FAISSå‘é‡ç´¢å¼•æ–‡ä»¶ï¼ˆå¯ä»¥é‡æ–°æ„å»ºï¼‰
            "faiss_index_domain_science.index",            # ä¸»ç´¢å¼•æ–‡ä»¶
            "faiss_index_domain_science_mapping.json",     # ç´¢å¼•æ˜ å°„æ–‡ä»¶
            
            # å…¶ä»–å¯èƒ½çš„ç´¢å¼•æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            "*.index",                                    # å…¶ä»–.indexæ–‡ä»¶
            "faiss_index_*",                              # å…¶ä»–FAISSç´¢å¼•æ–‡ä»¶
            
            # æœºå™¨å­¦ä¹ æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            "*.pkl",                                      # Python pickleæ–‡ä»¶
            "*.pickle",                                   # Python pickleæ–‡ä»¶
        ]
        
        # é‡è¦ï¼šä¸ä¼šè¢«åˆ é™¤çš„æ–‡ä»¶
        protected_files = [
            "file_storage/file_mapping.json",             # æ–‡ä»¶æ˜ å°„ï¼Œåˆ é™¤ä¼šå¯¼è‡´ä¸Šä¼ æ–‡ä»¶ä¸¢å¤±
        ]
        
        for pattern in safe_to_delete_patterns:
            for file_path in self.project_root.glob(pattern):
                try:
                    if file_path.is_file():
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å—ä¿æŠ¤çš„æ–‡ä»¶
                        is_protected = False
                        for protected_file in protected_files:
                            if file_path.name == protected_file.split('/')[-1]:
                                is_protected = True
                                break
                        
                        if is_protected:
                            logger.info(f"  âš ï¸  è·³è¿‡å—ä¿æŠ¤æ–‡ä»¶: {file_path.name}")
                            continue
                        
                        size = self.get_dir_size(file_path)
                        file_path.unlink()
                        self.log_cleaned("ç´¢å¼•æ–‡ä»¶", file_path, size)
                        cleaned_count += 1
                        logger.info(f"  âœ… å·²åˆ é™¤ç´¢å¼•æ–‡ä»¶: {file_path.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("ç´¢å¼•æ–‡ä»¶", file_path, str(e))
                    logger.error(f"  âŒ åˆ é™¤ç´¢å¼•æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        if cleaned_count > 0:
            logger.info("  ğŸ’¡ æç¤ºï¼šåˆ é™¤çš„ç´¢å¼•æ–‡ä»¶å¯ä»¥é€šè¿‡é‡æ–°æ„å»ºçŸ¥è¯†åº“æ¥é‡æ–°ç”Ÿæˆ")
        
        return cleaned_count
    
    def clean_storage_files(self) -> int:
        """æ¸…ç†å­˜å‚¨æ–‡ä»¶ï¼ˆåªæ¸…ç†å¯é‡æ–°ç”Ÿæˆçš„æ–‡ä»¶ï¼‰"""
        logger.info("ğŸ§¹ æ¸…ç†å­˜å‚¨æ–‡ä»¶...")
        cleaned_count = 0
        
        # é‡è¦ï¼šåªæ¸…ç†å¯ä»¥å®‰å…¨åˆ é™¤çš„ç›®å½•
        safe_to_clean_dirs = [
            # æ³¨æ„ï¼šuploads/ ç›®å½•å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šåœ¨æ­¤æ¸…ç†
            # æ³¨æ„ï¼šsessions/ ç›®å½•å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šåœ¨æ­¤æ¸…ç†
            self.project_root / "logs",         # æ—¥å¿—æ–‡ä»¶ï¼ˆå¯ä»¥é‡æ–°ç”Ÿæˆï¼‰
        ]
        
        # é‡è¦ï¼šä¸ä¼šæ¸…ç†çš„ç›®å½•
        protected_dirs = [
            self.project_root / "file_storage", # åŒ…å«ç”¨æˆ·ä¸Šä¼ çš„åŸå§‹æ–‡ä»¶ï¼Œæ— æ³•é‡æ–°ç”Ÿæˆ
            self.project_root / "uploads",      # ä¸Šä¼ ç›®å½•å—åˆ°ä¿æŠ¤
            self.project_root / "sessions",     # ä¼šè¯ç›®å½•å—åˆ°ä¿æŠ¤
        ]
        
        for storage_dir in safe_to_clean_dirs:
            if storage_dir.exists() and storage_dir.is_dir():
                try:
                    size = self.get_dir_size(storage_dir)
                    shutil.rmtree(storage_dir)
                    # é‡æ–°åˆ›å»ºç©ºç›®å½•
                    storage_dir.mkdir(exist_ok=True)
                    
                    self.log_cleaned("å­˜å‚¨ç›®å½•", storage_dir, size)
                    cleaned_count += 1
                    logger.info(f"  âœ… å·²æ¸…ç†å­˜å‚¨ç›®å½•: {storage_dir.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("å­˜å‚¨ç›®å½•", storage_dir, str(e))
                    logger.error(f"  âŒ æ¸…ç†å­˜å‚¨ç›®å½•å¤±è´¥ {storage_dir}: {e}")
        
        # æ£€æŸ¥å—ä¿æŠ¤çš„ç›®å½•
        for protected_dir in protected_dirs:
            if protected_dir.exists():
                logger.info(f"  âš ï¸  è·³è¿‡å—ä¿æŠ¤ç›®å½•: {protected_dir.name} (åŒ…å«ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶)")
        
        return cleaned_count
    
    def clean_test_files(self) -> int:
        """æ¸…ç†æµ‹è¯•äº§ç”Ÿçš„æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        cleaned_count = 0
        
        test_output_patterns = [
            # æ³¨æ„ï¼šhtmlcov/ ç›®å½•å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šåœ¨æ­¤æ¸…ç†
            ".coverage",
            ".coverage.*",
            "coverage.xml",
            "*.cover",
            "*.py,cover",
        ]
        
        for pattern in test_output_patterns:
            for path in self.project_root.glob(pattern):
                try:
                    if path.is_file():
                        size = self.get_dir_size(path)
                        path.unlink()
                        self.log_cleaned("æµ‹è¯•æ–‡ä»¶", path, size)
                        cleaned_count += 1
                        logger.info(f"  âœ… å·²åˆ é™¤æµ‹è¯•æ–‡ä»¶: {path.name} ({size:.2f} MB)")
                    elif path.is_dir():
                        size = self.get_dir_size(path)
                        shutil.rmtree(path)
                        self.log_cleaned("æµ‹è¯•ç›®å½•", path, size)
                        cleaned_count += 1
                        logger.info(f"  âœ… å·²åˆ é™¤æµ‹è¯•ç›®å½•: {path.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("æµ‹è¯•æ–‡ä»¶", path, str(e))
                    logger.error(f"  âŒ åˆ é™¤æµ‹è¯•æ–‡ä»¶å¤±è´¥ {path}: {e}")
        
        return cleaned_count
    
    def clean_dev_files(self) -> int:
        """æ¸…ç†å¼€å‘è°ƒè¯•æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†å¼€å‘è°ƒè¯•æ–‡ä»¶...")
        cleaned_count = 0
        
        dev_files = [
            "debug.md",
            "debug_*.md",
            "progress.md", 
            "progress_*.md",
            "æ„å»ºå®Œæˆè®°å½•.md",
            "è¿›åº¦.md",
        ]
        
        for pattern in dev_files:
            for file_path in self.project_root.glob(pattern):
                try:
                    if file_path.is_file():
                        size = self.get_dir_size(file_path)
                        file_path.unlink()
                        self.log_cleaned("å¼€å‘æ–‡ä»¶", file_path, size)
                        cleaned_count += 1
                        logger.info(f"  âœ… å·²åˆ é™¤å¼€å‘æ–‡ä»¶: {file_path.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("å¼€å‘æ–‡ä»¶", file_path, str(e))
                    logger.error(f"  âŒ åˆ é™¤å¼€å‘æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return cleaned_count
    
    def clean_project_records(self) -> int:
        """æ¸…ç†é¡¹ç›®è®°å½•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰"""
        logger.info("ğŸ§¹ æ¸…ç†é¡¹ç›®è®°å½•æ–‡ä»¶...")
        cleaned_count = 0
        
        # æ³¨æ„ï¼šé¡¹ç›®è®°å½•/ ç›®å½•å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šåœ¨æ­¤æ¸…ç†
        logger.info("  âš ï¸  é¡¹ç›®è®°å½•ç›®å½•å—åˆ°ä¿æŠ¤ï¼Œä¸ä¼šè¢«æ¸…ç†")
        
        return cleaned_count
    
    def clean_ai_config(self) -> int:
        """æ¸…ç†AIç›¸å…³é…ç½®ï¼ˆè·³è¿‡.claudeç›®å½•ï¼‰"""
        logger.info("ğŸ§¹ æ¸…ç†AIé…ç½®æ–‡ä»¶...")
        cleaned_count = 0
        
        # æ³¨æ„ï¼š.claudeç›®å½•åŒ…å«ç”¨æˆ·ä¸ªäººè®¾ç½®ï¼Œè·³è¿‡æ¸…ç†
        logger.info("  â„¹ï¸  è·³è¿‡.claudeç›®å½•ï¼ˆç”¨æˆ·ä¸ªäººè®¾ç½®ï¼‰")
        
        return cleaned_count
    
    def clean_ide_files(self) -> int:
        """æ¸…ç†IDEé…ç½®æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†IDEé…ç½®æ–‡ä»¶...")
        cleaned_count = 0
        
        ide_dirs = [
            self.project_root / ".vscode",
            self.project_root / ".idea",
        ]
        
        for ide_dir in ide_dirs:
            if ide_dir.exists():
                try:
                    size = self.get_dir_size(ide_dir)
                    shutil.rmtree(ide_dir)
                    self.log_cleaned("IDEé…ç½®", ide_dir, size)
                    cleaned_count += 1
                    logger.info(f"  âœ… å·²æ¸…ç†IDEé…ç½®ç›®å½•: {ide_dir.name} ({size:.2f} MB)")
                except Exception as e:
                    self.log_failed("IDEé…ç½®", ide_dir, str(e))
                    logger.error(f"  âŒ æ¸…ç†IDEé…ç½®å¤±è´¥ {ide_dir}: {e}")
        
        return cleaned_count
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        total_size = sum(item['size_mb'] for item in self.cleaned_items)
        total_items = len(self.cleaned_items)
        
        report = {
            'summary': {
                'total_items_cleaned': total_items,
                'total_size_mb': total_size,
                'failed_items': len(self.failed_items),
                'timestamp': time.time()
            },
            'cleaned_items': self.cleaned_items,
            'failed_items': self.failed_items
        }
        
        return report
    
    def print_report(self, report: Dict[str, Any]):
        """æ‰“å°æ¸…ç†æŠ¥å‘Š"""
        summary = report['summary']
        
        print("\n" + "="*60)
        print("ğŸ§¹ é¡¹ç›®æ¸…ç†æŠ¥å‘Š")
        print("="*60)
        print(f"âœ… æ¸…ç†é¡¹ç›®æ•°: {summary['total_items_cleaned']}")
        print(f"ğŸ’¾ é‡Šæ”¾ç©ºé—´: {summary['total_size_mb']:.2f} MB")
        print(f"âŒ å¤±è´¥é¡¹ç›®: {summary['failed_items']}")
        print("="*60)
        
        if summary['failed_items'] > 0:
            print("\nâš ï¸  æ¸…ç†å¤±è´¥çš„é¡¹ç›®:")
            for item in report['failed_items']:
                print(f"  - {item['type']}: {item['path']} ({item['error']})")
        
        print("\nğŸ‰ é¡¹ç›®æ¸…ç†å®Œæˆï¼ç°åœ¨å¯ä»¥å®‰å…¨åœ°æäº¤åˆ°GitHubäº†ã€‚")
    
    def clean_all(self, include_records: bool = False) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é¢æ¸…ç†"""
        logger.info("ğŸš€ å¼€å§‹é¡¹ç›®æ¸…ç†...")
        start_time = time.time()
        
        # æ‰§è¡Œå„ç§æ¸…ç†
        self.clean_temp_files()
        self.clean_cache_files()
        self.clean_model_files()
        self.clean_storage_files()
        self.clean_test_files()
        self.clean_dev_files()
        self.clean_ai_config()
        self.clean_ide_files()
        
        # æ³¨æ„ï¼šé¡¹ç›®è®°å½•ç›®å½•ç°åœ¨å—åˆ°ä¿æŠ¤ï¼Œä¸å†æ¸…ç†
        # å³ä½¿ä½¿ç”¨ --include-records å‚æ•°ä¹Ÿä¸ä¼šæ¸…ç†é¡¹ç›®è®°å½•
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        report['summary']['execution_time'] = time.time() - start_time
        
        # æ‰“å°æŠ¥å‘Š
        self.print_report(report)
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RS Agent MCP é¡¹ç›®æ¸…ç†å·¥å…·")
    parser.add_argument(
        "--include-records", 
        action="store_true",
        help="åŒæ—¶æ¸…ç†é¡¹ç›®è®°å½•æ–‡ä»¶"
    )
    parser.add_argument(
        "--project-root",
        type=str,
        help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = ProjectCleaner(args.project_root)
    
    # æ‰§è¡Œæ¸…ç†
    try:
        report = cleaner.clean_all(include_records=args.include_records)
        
        # é€€å‡ºç 
        exit_code = 0 if report['summary']['failed_items'] == 0 else 1
        exit(exit_code)
        
    except KeyboardInterrupt:
        logger.info("âš ï¸  æ¸…ç†è¢«ç”¨æˆ·ä¸­æ–­")
        exit(1)
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        exit(1)


if __name__ == "__main__":
    main()